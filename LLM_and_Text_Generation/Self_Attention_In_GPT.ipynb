{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb18a6cb",
   "metadata": {},
   "source": [
    "### Implement Self-Attention mechanism in GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ef71e",
   "metadata": {},
   "source": [
    "#### Multi Head Self-Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4436430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    \"\"\" A Vanilla Multi-Head Self-Attention layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "\n",
    "        # key, query, value projections for all heads\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        \n",
    "        # output projection\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "        # Casual mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass for the multi-head masked self-attention layer.\n",
    "\n",
    "        In this exercise, we include lots of print statements and checks to help you\n",
    "        understand the code and the shapes of the tensors. When actually training\n",
    "        such a model you would not log this information to the console.\n",
    "        \"\"\"\n",
    "\n",
    "        # batch size, sequence length (in tokens), embedding dimensionality (n_embd per token)\n",
    "        B, T, C = x.size()\n",
    "        hs = C // self.n_head  # head size\n",
    "\n",
    "        # print some debug information\n",
    "        print(f\"batch size: {B}\")\n",
    "        print(f\"sequence length: {T}\")\n",
    "        print(f\"embedding dimensionality: {C}\")\n",
    "        print(f\"number of heads: {self.n_head}\")\n",
    "        print(f\"head size: {hs}\")\n",
    "\n",
    "        # Calculate the query, key, and value matrices for all the heads in the batch and move head forward to be the batch dimension\n",
    "        # The resulting dims for k, q, and v are (B, n_head, T, hs)\n",
    "        k = self.key(x).view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        q = self.query(x).view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        v = self.value(x).view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "\n",
    "        print(\"=== Calculate MatrixMultiplication(Q, K_T) / sqrt(d_k) ===\")\n",
    "        k_t = k.transpose(-2, -1)\n",
    "        print(\"Shape of K_T:\", k_t.size())\n",
    "        d_k = k.size(-1)\n",
    "        print(\"d_k:\", d_k)\n",
    "\n",
    "        # Matrix multiplication to get the raw attention scores.\n",
    "        att = (q @ k_t) / math.sqrt(d_k)  # (B, n_head, T, T)\n",
    "\n",
    "        print(f\"q.shape: {q.shape}\")\n",
    "        print(f\"k_t.shape: {k_t.shape}\")\n",
    "        print(f\"d_k: {d_k}\")\n",
    "        print(f\"att.shape: {att.shape}\")\n",
    "\n",
    "        print(\"=== Apply the attention mask ===\")\n",
    "        masked_fill_value = float(\"-inf\")\n",
    "        \n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, masked_fill_value)\n",
    "\n",
    "        # Show the result of applying the mask\n",
    "        print(f\"att: {att}\")\n",
    "\n",
    "        print(\"=== Softmax ===\")\n",
    "        att = F.softmax(att, dim=-1)\n",
    "\n",
    "        att = self.attn_dropout(att)\n",
    "\n",
    "        # Show the result of applying the softmax and check that\n",
    "        # the sum of the attention weights in each row is 1\n",
    "        print(f\"att.shape: {att.shape}\")\n",
    "        print(f\"att: {att}\")\n",
    "        print(f\"att.sum(dim=-1): {att.sum(dim=-1)}\")\n",
    "        att_rows_sum_to_one = all(\n",
    "            ((att.sum(dim=-1) - 1.0) ** 2 < 1e-6).flatten().tolist()\n",
    "        )\n",
    "        print(f\"att_rows_sum_to_one: {att_rows_sum_to_one}\")\n",
    "        if not att_rows_sum_to_one:\n",
    "            raise ValueError(\n",
    "                \"Attention weight rows do not sum to 1. Perhaps the softmax dimension or masked_fill_value is not correct?\"\n",
    "            )\n",
    "        \n",
    "        print(\"=== Calculate final attention ===\")\n",
    "        y = att @ v\n",
    "\n",
    "        print(f\"y.shape: {y.shape}\")\n",
    "\n",
    "        # Re-assemble all head outputs side by side\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.proj(y))\n",
    "        print(f\"Final output shape: {y.shape}\")\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e2c26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    vocab_size = 11\n",
    "    block_size = 5\n",
    "    # n_layer = 1 # not used here\n",
    "    n_head = 4\n",
    "    n_embd = 12\n",
    "\n",
    "    attn_pdrop = 0.0\n",
    "    resid_pdrop = 0.0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c2ee26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadSelfAttention(GPTConfig())\n",
    "x = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            # 12-dimensional embeddings (4 heads @ 3 dim. each) for each of 5 tokens\n",
    "            [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0],\n",
    "            [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "            [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "            [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "            [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "177403a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 12])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9714b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all parameters to 0.1\n",
    "for weight in attention.parameters():\n",
    "    nn.init.constant_(weight, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bb54fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode to disable dropout\n",
    "# attention.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "291f6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1\n",
      "sequence length: 5\n",
      "embedding dimensionality: 12\n",
      "number of heads: 4\n",
      "head size: 3\n",
      "=== Calculate MatrixMultiplication(Q, K_T) / sqrt(d_k) ===\n",
      "Shape of K_T: torch.Size([1, 4, 3, 5])\n",
      "d_k: 3\n",
      "q.shape: torch.Size([1, 4, 5, 3])\n",
      "k_t.shape: torch.Size([1, 4, 3, 5])\n",
      "d_k: 3\n",
      "att.shape: torch.Size([1, 4, 5, 5])\n",
      "=== Apply the attention mask ===\n",
      "att: tensor([[[[16.6450,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,  2.9272]],\n",
      "\n",
      "         [[16.6450,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,  2.9272]],\n",
      "\n",
      "         [[16.6450,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,  2.9272]],\n",
      "\n",
      "         [[16.6450,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,    -inf,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,    -inf,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,    -inf],\n",
      "          [ 6.9802,  2.9272,  2.9272,  2.9272,  2.9272]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "=== Softmax ===\n",
      "att.shape: torch.Size([1, 4, 5, 5])\n",
      "att: tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9829, 0.0171, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9664, 0.0168, 0.0168, 0.0000, 0.0000],\n",
      "          [0.9505, 0.0165, 0.0165, 0.0165, 0.0000],\n",
      "          [0.9350, 0.0162, 0.0162, 0.0162, 0.0162]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9829, 0.0171, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9664, 0.0168, 0.0168, 0.0000, 0.0000],\n",
      "          [0.9505, 0.0165, 0.0165, 0.0165, 0.0000],\n",
      "          [0.9350, 0.0162, 0.0162, 0.0162, 0.0162]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9829, 0.0171, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9664, 0.0168, 0.0168, 0.0000, 0.0000],\n",
      "          [0.9505, 0.0165, 0.0165, 0.0165, 0.0000],\n",
      "          [0.9350, 0.0162, 0.0162, 0.0162, 0.0162]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9829, 0.0171, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9664, 0.0168, 0.0168, 0.0000, 0.0000],\n",
      "          [0.9505, 0.0165, 0.0165, 0.0165, 0.0000],\n",
      "          [0.9350, 0.0162, 0.0162, 0.0162, 0.0162]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "att.sum(dim=-1): tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]]], grad_fn=<SumBackward1>)\n",
      "att_rows_sum_to_one: True\n",
      "=== Calculate final attention ===\n",
      "y.shape: torch.Size([1, 4, 5, 3])\n",
      "Final output shape: torch.Size([1, 5, 12])\n"
     ]
    }
   ],
   "source": [
    "# Perform a forward pass\n",
    "y = attention(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1a666b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Showing the input and output ===\n",
      "tensor([[[1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
      "tensor([[[3.8200, 3.8200, 3.8200, 3.8200, 3.8200, 3.8200, 3.8200, 3.8200,\n",
      "          3.8200, 3.8200, 3.8200, 3.8200],\n",
      "         [3.7831, 3.7831, 3.7831, 3.7831, 3.7831, 3.7831, 3.7831, 3.7831,\n",
      "          3.7831, 3.7831, 3.7831, 3.7831],\n",
      "         [3.7475, 3.7475, 3.7475, 3.7475, 3.7475, 3.7475, 3.7475, 3.7475,\n",
      "          3.7475, 3.7475, 3.7475, 3.7475],\n",
      "         [3.7130, 3.7130, 3.7130, 3.7130, 3.7130, 3.7130, 3.7130, 3.7130,\n",
      "          3.7130, 3.7130, 3.7130, 3.7130],\n",
      "         [3.6797, 3.6797, 3.6797, 3.6797, 3.6797, 3.6797, 3.6797, 3.6797,\n",
      "          3.6797, 3.6797, 3.6797, 3.6797]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Showing the input and output ===\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a33fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking gradients ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Checking gradients ===\")\n",
    "loss = y.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6db76f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(224.9195, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93821dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if nan in y\n",
    "if torch.isnan(y).any().item():\n",
    "    raise ValueError(\n",
    "        \"It appears that the output contains NaNs. Perhaps the softmax dimension is incorrect?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a74fd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = [\n",
    "    int((attention.query.weight.grad**2).sum().item()),\n",
    "    int((attention.query.bias.grad**2).sum().item()),\n",
    "    int((attention.key.weight.grad**2).sum().item()),\n",
    "    int((attention.key.bias.grad**2).sum().item()),\n",
    "    int((attention.value.weight.grad**2).sum().item()),\n",
    "    int((attention.value.bias.grad**2).sum().item()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efe87a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients: [161, 13, 294, 0, 37187, 432]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradients:\", gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "113020ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸš€ðŸš€ðŸš€\n"
     ]
    }
   ],
   "source": [
    "if gradients == [161, 13, 294, 0, 37187, 432]:\n",
    "    print(\"Success! ðŸš€ðŸš€ðŸš€\")\n",
    "elif gradients == [1, 0, 2, 0, 38787, 432]:\n",
    "    raise RuntimeError(\n",
    "        \"There is an error in your implementation. Please check your code. Did you remember to divide by the square root of d_k?\"\n",
    "    )\n",
    "elif gradients[-1] == 432:\n",
    "    raise RuntimeError(\n",
    "        \"There is an error in your implementation. Please check your code. Did you use -inf as the masked_fill_value?\"\n",
    "    )\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"There is an error in your implementation. Please check your code.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f17ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
